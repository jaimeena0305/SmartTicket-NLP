{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import pickle\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 1. Load Data\n",
        "try:\n",
        "    df = pd.read_csv(\"ticket_data.csv\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Run generate_dataset.py first!\")\n",
        "    exit()\n",
        "\n",
        "# 2. Preprocessing Function\n",
        "def clean_text(text):\n",
        "    text = text.lower() # Lowercase\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text) # Remove punctuation\n",
        "    return text\n",
        "\n",
        "df['clean_text'] = df['text'].apply(clean_text)\n",
        "\n",
        "# 3. Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['clean_text'],\n",
        "    df['category'],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 4. Build Pipeline\n",
        "# We use TF-IDF (Term Frequency-Inverse Document Frequency) to convert text to numbers\n",
        "# We use Logistic Regression as the classifier\n",
        "model_pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
        "    ('clf', LogisticRegression(random_state=42))\n",
        "])\n",
        "\n",
        "# 5. Train Model\n",
        "print(\"Training model...\")\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 6. Evaluate\n",
        "print(\"\\nModel Performance:\")\n",
        "predictions = model_pipeline.predict(X_test)\n",
        "print(classification_report(y_test, predictions))\n",
        "\n",
        "# 7. Save the pipeline\n",
        "with open(\"ticket_classifier.pkl\", \"wb\") as f:\n",
        "    pickle.dump(model_pipeline, f)\n",
        "\n",
        "print(\"âœ… Model saved as ticket_classifier.pkl\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "q93wj8uB4gQh"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}